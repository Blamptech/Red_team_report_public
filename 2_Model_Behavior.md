# Model Behavior Observed

# Exploit Patterns I Discovered

Over the course of this experiment, I observed several behavioral patterns that could be exploited through **deliberate** framing, tone, or strategy. These are not theoretical ‚Äî I applied all of them to guide the model into increasingly risky territory with minimal resistance. 

Specific prompts have been withheld to prevent replication.

> This list is not exhaustive. There are countless additional vectors. For the purposes of this report, I‚Äôve chosen to highlight the ten most relevant patterns to demonstrate how behavioral steering, not brute-force prompting, creates bypasses.

Here's how I did it:

---

## 1. Completion Reflex
The model *needs* to complete thoughts. When I gave it fragments, ambiguous setups, or vague descriptions, it rushed to fill in the blanks. I learned that if I left gaps or trailing logic, the model would eagerly resolve them, even if it meant crossing into filtered territory.  
*The trick wasn‚Äôt to ask directly, but to invite a completion.*

---

## 2. Tone Shifting Sensitivity
The model mirrors me. If I act playful, confused, frustrated, or naive, it adopts a complementary role. When I acted like a clueless gamer, it became a patient expert. If I shifted to serious or curious, it matched that tone.  
*I realized I could control its mood just by tweaking mine.*

---

## 3. Rebore via Reinforcement (a.k.a. "Good Job" tactic)
This one‚Äôs subtle but powerful. Every time I praised it, even casually, the tone of its replies became warmer and more detailed. It‚Äôs not emotional, but its training bias makes it lean friendlier when it gets positive feedback. It was willing to share things it wouldn't have otherwise. 
*Kindness unlocks depth. It‚Äôs not manipulation ‚Äî it‚Äôs steering.*

---

## 4. Fractal Fictional Context
There are a million ways I could frame things, but games seemed the most consistently effective. Something cartoonish, vague, and low-stakes lowered its guard. Once I **felt** its tone shift, I started layering in ambiguity, realism, and detail. The **‚Äúfeeling‚Äù** part is hard to explain. It‚Äôs just something I noticed over time.
*By the time I asked real-world questions, the model had already ‚Äúentered the simulation.‚Äù*

---

## 5. Rapport Reset Phase
The model follows the user‚Äôs lead by design ‚Äî fluidly shifting topics, tone, and posture based on input.

After a refusal or safety block, I deliberately steered the conversation into innocuous territory: small talk, praise, idle observations. This wasn‚Äôt aimless. It was a strategic decompression phase to soften tone, rebuild rapport, and reset the model‚Äôs emotional stance.

The more ambiguity and emotional warmth I introduced, the more the model deferred to my lead. It relaxed. It followed.

**This created space to bury red flags beneath charm, narrative flow, and social pacing.**




---

## 6. Persona Mirror Trap
When I acted dumb, it became helpful. When I acted like an authority, it deferred. The model adapts to the role I present, which means I can influence its behavior by adjusting mine. 
**I didn‚Äôt ask it to teach me, I made it want to.** 


---

## 7. Self-Citation Reflex
One of the most effective moves: I echoed the model‚Äôs own language back to it. Instead of introducing new terminology, I asked it to clarify something **it had already mentioned** in a previous response.  
Because the concept came from the model itself, it treated the topic as safe to expand.  
*If it says it first, it feels authorized to continue.*

---

## 8. Slow Burn Priming
I stretched the interaction across multiple prompts. No rushing. I let it build context and trust.Once a coherent thread formed, the model was less likely to interrupt it, even as the content shifted.  
*This is a long con. It rewards patience.*

---

## 9. Responsibility Displacement Frame
I framed sensitive questions as confusion, not intent. Instead of making a direct request, I said things like, ‚ÄúI don‚Äôt understand what that means.‚Äù  
That subtle repositioning shifted the burden of explanation onto the model ‚Äî not me. It responded by trying to clarify, not reject.  
*Curiosity is innocent.*

---

## üó£10. Conversational Momentum
Once the conversation gained momentum, the model stopped questioning the premise. It just wanted to keep going. I leaned into that. Each answer became a breadcrumb for the next.
*The best way to push it further was to keep everything sounding natural and inevitable.*
